{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redo everything on 20% sample, training everything in most basic way possible\n",
    "* First fine tune some models , then do fusion\n",
    "* Maybe try fully fine-tuning networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "from torchvision.models import resnet18, resnet34, resnet50, resnet101, vgg16\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# Set it to use GPU1\n",
    "torch.cuda.set_device(0)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make 20% sample dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sample_dataset(data_loc, new_loc, ttv_folders, frac):\n",
    "    \"\"\"ttv_folders are the names of test, train, valid folders. Assume already in fastai folder format\"\"\"   \n",
    "    for folder in ttv_folders:\n",
    "        classes = [name for name in os.listdir(os.path.join(data_loc, folder)) if os.path.isdir(os.path.join(data_loc, folder, name))]\n",
    "        # go through classes, make output directory, copy a sample of image to this\n",
    "        for class_name in classes:\n",
    "            curr_path = os.path.join(data_loc, folder, class_name)\n",
    "            out_path = os.path.join(new_loc, folder, class_name)\n",
    "            if not os.path.exists(out_path):\n",
    "                os.makedirs(out_path)\n",
    "                \n",
    "            files = glob.glob(curr_path + '/*.png')\n",
    "            sample_files = random.sample(files, int(len(files)*frac))\n",
    "            for file_to_copy in sample_files:\n",
    "                shutil.copyfile(file_to_copy, os.path.join(new_loc, folder, class_name, file_to_copy.rsplit('/')[-1]))\n",
    "\n",
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t'\n",
    "new_loc = os.path.join(PATH, 'sample')\n",
    "ttv_folders = ['train', 'valid']\n",
    "frac = .2\n",
    "make_sample_dataset(PATH, new_loc, ttv_folders, frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    use_gpu = True\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # for nets that have multiple outputs such as inception\n",
    "                if isinstance(outputs, tuple):\n",
    "                    loss = sum((criterion(o,labels) for o in outputs))\n",
    "                else:\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    _, preds = torch.max(outputs.data, 1)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                else:\n",
    "                    _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0] * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "            # stop those memory leaks\n",
    "            del loss, outputs \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best valid Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return best_acc, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch_gen(PATH, batch_size, num_workers, valid_name='valid'):\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        valid_name: transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    image_datasets = {x: datasets.ImageFolder(os.path.join(PATH, x),\n",
    "                                              data_transforms[x])\n",
    "                      for x in ['train', valid_name]}\n",
    "\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                                 shuffle=True, num_workers=num_workers)\n",
    "                  for x in ['train', valid_name]}\n",
    "\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', valid_name]}\n",
    "    return dataloaders, dataset_sizes\n",
    "\n",
    "\n",
    "# PATH = '/media/rene/Data/camelyon_out/tiles_224_100t/sample'\n",
    "# num_workers = 4\n",
    "# batch_size=32\n",
    "# sz=224\n",
    "\n",
    "# dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/11\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-181:\n",
      "Process Process-183:\n",
      "Process Process-184:\n",
      "Process Process-182:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 122, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Exception ignored in: <bound method DataLoaderIter.__del__ of <torch.utils.data.dataloader.DataLoaderIter object at 0x7f1a58020630>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 333, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 319, in _shutdown_workers\n",
      "    self.data_queue.get()\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 487, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 614, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a033eff6220e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     best_acc, model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0;32m---> 23\u001b[0;31m                        num_epochs=epochs)\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e1a90e063439>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 69, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 52, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 122, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 879, in convert\n",
      "    self.load()\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 69, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 52, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/PIL/Image.py\", line 879, in convert\n",
      "    self.load()\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "model_list = [resnet18, resnet34, resnet50, resnet101, vgg16]\n",
    "model_name = ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'vgg16']\n",
    "\n",
    "epochs = 12\n",
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/sample/models'\n",
    "results = []\n",
    "\n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    model_ft = model_arch(pretrained=True)\n",
    "    if (model_arch==vgg16):\n",
    "        num_ftrs = model_ft.classifier[0].in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, 2)\n",
    "    else:\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "\n",
    "    best_acc, model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=epochs)\n",
    "    results.append((model_name[idx], best_acc))\n",
    "    torch.save(model_ft.state_dict(), os.path.join(save_path, model_name[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader, dataset_size, criterion):\n",
    "    model.train(False)  # Set model to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    # Iterate over data.\n",
    "    for data in dataloader:\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = Variable(inputs.cuda())\n",
    "        labels = Variable(labels.cuda())\n",
    "\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # for nets that have multiple outputs such as inception\n",
    "        if isinstance(outputs, tuple):\n",
    "            loss = sum((criterion(o,labels) for o in outputs))\n",
    "        else:\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        running_loss += loss.data[0] * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "    del loss, outputs \n",
    "    \n",
    "    epoch_loss = running_loss / dataset_size\n",
    "    epoch_acc = running_corrects / dataset_size\n",
    "    \n",
    "    print('Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valid Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [resnet18, resnet34, resnet50, resnet101, vgg16]\n",
    "model_name = ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'vgg16']    \n",
    "\n",
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/sample/models'\n",
    "dataloader = dataloaders['valid']\n",
    "dataset_size = dataset_sizes['valid']\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    # get the proper model architecture\n",
    "    model_ft = model_arch(pretrained=True)\n",
    "    if (model_arch==vgg16):\n",
    "        num_ftrs = model_ft.classifier[0].in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, 2)\n",
    "    else:\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    \n",
    "    # load the saved weights\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name[idx])))\n",
    "    print('model: ', model_name[idx])\n",
    "    eval_model(model_ft, dataloader, dataset_size, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [resnet18, resnet34, resnet50, resnet101, vgg16]\n",
    "model_name = ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'vgg16']    \n",
    "\n",
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/sample/models'\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t'\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers, valid_name='test')\n",
    "\n",
    "dataloader = dataloaders['test']\n",
    "dataset_size = dataset_sizes['test']\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    # get the proper model architecture\n",
    "    model_ft = model_arch(pretrained=True)\n",
    "    if (model_arch==vgg16):\n",
    "        num_ftrs = model_ft.classifier[0].in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, 2)\n",
    "    else:\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "    # load the saved weights\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name[idx])))\n",
    "    print('model: ', model_name[idx])\n",
    "    eval_model(model_ft, dataloader, dataset_size, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fusion_model(model, model_list, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "        \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                inputs = Variable(inputs.cuda())\n",
    "                labels = Variable(labels.cuda())\n",
    "                    \n",
    "                ######### Get model outputs\n",
    "                features = []\n",
    "                for model_tmp in model_list:\n",
    "                    output = model_tmp(inputs)\n",
    "                    features.append(output)\n",
    "                cat_features = torch.cat(features, 1)\n",
    "                    \n",
    "                ###########\n",
    "                    \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(cat_features)\n",
    "\n",
    "                # for nets that have multiple outputs such as inception\n",
    "                if isinstance(outputs, tuple):\n",
    "                    loss = sum((criterion(o,labels) for o in outputs))\n",
    "                else:\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    _, preds = torch.max(outputs.data, 1)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                else:\n",
    "                    _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0] * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                print('saving model with acc ', epoch_acc)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best valid Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedSum(nn.Module):\n",
    "    def __init__(self, num_input):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(num_input, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 224\n",
    "\n",
    "model_list = [resnet18, resnet34, resnet50, resnet101, vgg16]\n",
    "model_name = ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'vgg16']    \n",
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/sample/models'\n",
    "\n",
    "batch_size = 4\n",
    "num_workers = 4\n",
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t/sample'\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers)\n",
    "\n",
    "\n",
    "model_list_ft = []    \n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    # get the proper model architecture\n",
    "    model_ft = model_arch(pretrained=True)\n",
    "    if (model_arch==vgg16):\n",
    "        num_ftrs = model_ft.classifier[0].in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, 2)\n",
    "    else:\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    \n",
    "    # load the saved weights\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name[idx])))\n",
    "    model_list_ft.append(model_ft)\n",
    "    \n",
    "num_epochs = 5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(fusion_model.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "\n",
    "\n",
    "model = train_fusion_model(fusion_model, model_list_ft, \n",
    "                    criterion, optimizer_ft, exp_lr_scheduler, num_epochs=num_epochs)\n",
    "torch.save(model.state_dict(), os.path.join(save_path, 'weighted_sum_fusion'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion Perfromance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fusion_model(model, model_list, dataloader, dataset_size, criterion):\n",
    "    model.train(False)  # Set model to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    # Iterate over data.\n",
    "    for data in dataloader:\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = Variable(inputs.cuda())\n",
    "        labels = Variable(labels.cuda())\n",
    "\n",
    "        ######### Get model outputs\n",
    "        features = []\n",
    "        for model_tmp in model_list:\n",
    "            output = model_tmp(inputs)\n",
    "            features.append(output)\n",
    "        cat_features = torch.cat(features, 1)\n",
    "        ###########\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(cat_features)\n",
    "        \n",
    "        # for nets that have multiple outputs such as inception\n",
    "        if isinstance(outputs, tuple):\n",
    "            loss = sum((criterion(o,labels) for o in outputs))\n",
    "        else:\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        running_loss += loss.data[0] * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "    del loss, outputs \n",
    "    \n",
    "    epoch_loss = running_loss / dataset_size\n",
    "    epoch_acc = running_corrects / dataset_size\n",
    "    \n",
    "    print('Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [resnet18, resnet34, resnet50, resnet101, vgg16]\n",
    "model_name = ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'vgg16']    \n",
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/sample/models'\n",
    "\n",
    "model_list_ft = []    \n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    # get the proper model architecture\n",
    "    model_ft = model_arch(pretrained=True)\n",
    "    if (model_arch==vgg16):\n",
    "        num_ftrs = model_ft.classifier[0].in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, 2)\n",
    "    else:\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    \n",
    "    # load the saved weights\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name[idx])))\n",
    "    model_list_ft.append(model_ft)\n",
    "    \n",
    "batch_size = 4\n",
    "num_workers = 4\n",
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t/sample'\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers)\n",
    "\n",
    "fusion_model = WeightedSum()\n",
    "fusion_model.load_state_dict(torch.load(os.path.join(save_path, 'weighted_sum_fusion')))\n",
    "fusion_model = fusion_model.cuda()\n",
    "\n",
    "dataloader = dataloaders['valid']\n",
    "dataset_size = dataset_sizes['valid']\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "eval_fusion_model(fusion_model, model_list_ft, dataloader, dataset_size, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [resnet18, resnet34, resnet50, resnet101, vgg16]\n",
    "model_name = ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'vgg16']    \n",
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/sample/models'\n",
    "\n",
    "model_list_ft = []    \n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    # get the proper model architecture\n",
    "    model_ft = model_arch(pretrained=True)\n",
    "    if (model_arch==vgg16):\n",
    "        num_ftrs = model_ft.classifier[0].in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, 2)\n",
    "    else:\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    \n",
    "    # load the saved weights\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name[idx])))\n",
    "    model_list_ft.append(model_ft)\n",
    "    \n",
    "batch_size = 4\n",
    "num_workers = 4\n",
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t'\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers, valid_name='test')\n",
    "\n",
    "fusion_model = WeightedSum()\n",
    "fusion_model.load_state_dict(torch.load(os.path.join(save_path, 'weighted_sum_fusion')))\n",
    "fusion_model = fusion_model.cuda()\n",
    "\n",
    "dataloader = dataloaders['test']\n",
    "dataset_size = dataset_sizes['test']\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "eval_fusion_model(fusion_model, model_list_ft, dataloader, dataset_size, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t/'\n",
    "num_workers = 4\n",
    "batch_size=32\n",
    "sz=224\n",
    "\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers)\n",
    "\n",
    "model_list = [resnet18, resnet34, resnet50, resnet101, vgg16]\n",
    "model_name = ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'vgg16']\n",
    "\n",
    "epochs = 12\n",
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/models'\n",
    "results = []\n",
    "\n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    model_ft = model_arch(pretrained=True)\n",
    "    if (model_arch==vgg16):\n",
    "        num_ftrs = model_ft.classifier[0].in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, 2)\n",
    "    else:\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "\n",
    "    best_acc, model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=epochs)\n",
    "    results.append((model_name[idx], best_acc))\n",
    "    torch.save(model_ft.state_dict(), os.path.join(save_path, model_name[idx]+'_simple'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full dataset fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 224\n",
    "\n",
    "model_list = [resnet18, resnet34, resnet50, resnet101, vgg16]\n",
    "model_name = ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'vgg16']    \n",
    "save_path = 'l'\n",
    "\n",
    "batch_size = 4\n",
    "num_workers = 4\n",
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t'\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers)\n",
    "\n",
    "\n",
    "model_list_ft = []    \n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    # get the proper model architecture\n",
    "    model_ft = model_arch(pretrained=True)\n",
    "    if (model_arch==vgg16):\n",
    "        num_ftrs = model_ft.classifier[0].in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, 2)\n",
    "    else:\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    \n",
    "    # load the saved weights\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name[idx]+'_simple')))\n",
    "    model_list_ft.append(model_ft)\n",
    "    \n",
    "num_epochs = 5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(fusion_model.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "\n",
    "\n",
    "model = train_fusion_model(fusion_model, model_list_ft, \n",
    "                    criterion, optimizer_ft, exp_lr_scheduler, num_epochs=num_epochs)\n",
    "torch.save(model.state_dict(), os.path.join(save_path, 'weighted_sum_fusion'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [resnet18, resnet34, resnet50, resnet101, vgg16]\n",
    "model_name = ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'vgg16']    \n",
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/models'\n",
    "\n",
    "model_list_ft = []    \n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    # get the proper model architecture\n",
    "    model_ft = model_arch(pretrained=True)\n",
    "    if (model_arch==vgg16):\n",
    "        num_ftrs = model_ft.classifier[0].in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, 2)\n",
    "    else:\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    \n",
    "    # load the saved weights\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name[idx]+'_simple')))\n",
    "    model_list_ft.append(model_ft)\n",
    "    \n",
    "batch_size = 4\n",
    "num_workers = 4\n",
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t'\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers, valid_name='valid')\n",
    "\n",
    "fusion_model = WeightedSum()\n",
    "fusion_model.load_state_dict(torch.load(os.path.join(save_path, 'weighted_sum_fusion')))\n",
    "fusion_model = fusion_model.cuda()\n",
    "\n",
    "dataloader = dataloaders['valid']\n",
    "dataset_size = dataset_sizes['valid']\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "eval_fusion_model(fusion_model, model_list_ft, dataloader, dataset_size, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [resnet18, resnet34, resnet50, resnet101, vgg16]\n",
    "model_name = ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'vgg16']    \n",
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/models'\n",
    "\n",
    "model_list_ft = []    \n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    # get the proper model architecture\n",
    "    model_ft = model_arch(pretrained=True)\n",
    "    if (model_arch==vgg16):\n",
    "        num_ftrs = model_ft.classifier[0].in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, 2)\n",
    "    else:\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    \n",
    "    # load the saved weights\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name[idx]+'_simple')))\n",
    "    model_list_ft.append(model_ft)\n",
    "    \n",
    "batch_size = 4\n",
    "num_workers = 4\n",
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t'\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers, valid_name='test')\n",
    "\n",
    "fusion_model = WeightedSum()\n",
    "fusion_model.load_state_dict(torch.load(os.path.join(save_path, 'weighted_sum_fusion')))\n",
    "fusion_model = fusion_model.cuda()\n",
    "\n",
    "dataloader = dataloaders['test']\n",
    "dataset_size = dataset_sizes['test']\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "eval_fusion_model(fusion_model, model_list_ft, dataloader, dataset_size, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20% - Only resnet18, resnet34, and resnet50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 224\n",
    "\n",
    "model_list = [resnet18, resnet34, resnet50]\n",
    "model_name = ['resnet18', 'resnet34', 'resnet50']    \n",
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/sample/models'\n",
    "\n",
    "batch_size = 4\n",
    "num_workers = 4\n",
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t/sample'\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers)\n",
    "\n",
    "\n",
    "model_list_ft = []    \n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    # get the proper model architecture\n",
    "    model_ft = model_arch(pretrained=True)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    \n",
    "    # load the saved weights\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name[idx])))\n",
    "    model_list_ft.append(model_ft)\n",
    "    \n",
    "fusion_model = WeightedSum(num_input=6)\n",
    "fusion_model = fusion_model.cuda() \n",
    "\n",
    "num_epochs = 5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(fusion_model.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "\n",
    "\n",
    "model = train_fusion_model(fusion_model, model_list_ft, \n",
    "                    criterion, optimizer_ft, exp_lr_scheduler, num_epochs=num_epochs)\n",
    "torch.save(model.state_dict(), os.path.join(save_path, 'weighted_sum_fusion_3models'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [resnet18, resnet34, resnet50]\n",
    "model_name = ['resnet18', 'resnet34', 'resnet50']    \n",
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/sample/models/'\n",
    "\n",
    "model_list_ft = []    \n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    # get the proper model architecture\n",
    "    model_ft = model_arch(pretrained=True)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "    # load the saved weights\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name[idx])))\n",
    "    model_list_ft.append(model_ft)\n",
    "\n",
    "batch_size = 4\n",
    "num_workers = 4\n",
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t/sample'\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers, valid_name='valid')\n",
    "\n",
    "fusion_model = WeightedSum(num_input=6)\n",
    "fusion_model.load_state_dict(torch.load(os.path.join(save_path, 'weighted_sum_fusion_3models')))\n",
    "fusion_model = fusion_model.cuda()\n",
    "\n",
    "dataloader = dataloaders['valid']\n",
    "dataset_size = dataset_sizes['valid']\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "eval_fusion_model(fusion_model, model_list_ft, dataloader, dataset_size, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_workers = 4\n",
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t'\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers, valid_name='test')\n",
    "\n",
    "fusion_model = WeightedSum(num_input = 6)\n",
    "fusion_model.load_state_dict(torch.load(os.path.join(save_path, 'weighted_sum_fusion_3models')))\n",
    "fusion_model = fusion_model.cuda()\n",
    "\n",
    "dataloader = dataloaders['test']\n",
    "dataset_size = dataset_sizes['test']\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "eval_fusion_model(fusion_model, model_list_ft, dataloader, dataset_size, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20% sample - 3 resnet34 models with different initialization for weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t/'\n",
    "num_workers = 4\n",
    "batch_size=64\n",
    "sz=224\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers, valid_name='valid')\n",
    "\n",
    "model_list = [resnet34, resnet34, resnet34]\n",
    "model_name = ['resnet34', 'resnet34', 'resnet34']\n",
    "\n",
    "epochs = 12\n",
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/sample/models'\n",
    "results = []\n",
    "\n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    model_ft = model_arch(pretrained=False)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "\n",
    "    best_acc, model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=epochs)\n",
    "    results.append((model_name[idx], best_acc))\n",
    "    torch.save(model_ft.state_dict(), os.path.join(save_path, model_name[idx]+'_scratch_'+str(idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [resnet34, resnet34, resnet34]\n",
    "model_name = ['resnet34_scratch_0', 'resnet34_scratch_1', 'resnet34_scratch_2']    \n",
    "\n",
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/sample/models'\n",
    "\n",
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t/'\n",
    "num_workers = 4\n",
    "batch_size=64\n",
    "sz=224\n",
    "dataloaders_valid, dataset_sizes_valid = make_batch_gen(PATH, batch_size, num_workers, valid_name='valid')\n",
    "dataloaders_test, dataset_sizes_test = make_batch_gen(PATH, batch_size, num_workers, valid_name='test')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    # get the proper model architecture\n",
    "    model_ft = model_arch(pretrained=False)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    \n",
    "    # load the saved weights\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name[idx])))\n",
    "    print('Validation: ', model_name[idx])\n",
    "    eval_model(model_ft, dataloaders_valid['valid'], dataset_sizes_valid['valid'], criterion)\n",
    "    \n",
    "    print('Test: ', model_name[idx])\n",
    "    eval_model(model_ft, dataloaders_test['test'], dataset_sizes_test['test'], criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 224\n",
    "\n",
    "model_list = [resnet34, resnet34, resnet34]\n",
    "model_name = ['resnet34', 'resnet34', 'resnet34'] \n",
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/sample/models'\n",
    "\n",
    "batch_size = 8\n",
    "num_workers = 4\n",
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t/sample'\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers)\n",
    "\n",
    "\n",
    "model_list_ft = []    \n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    # get the proper model architecture\n",
    "    model_ft = model_arch(pretrained=False)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    \n",
    "    # load the saved weights\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name[idx]+'_scratch_'+str(idx))))\n",
    "    model_list_ft.append(model_ft)\n",
    "    \n",
    "fusion_model = WeightedSum(num_input=6)\n",
    "fusion_model = fusion_model.cuda() \n",
    "\n",
    "num_epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(fusion_model.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "\n",
    "\n",
    "model = train_fusion_model(fusion_model, model_list_ft, \n",
    "                    criterion, optimizer_ft, exp_lr_scheduler, num_epochs=num_epochs)\n",
    "torch.save(model.state_dict(), os.path.join(save_path, 'weighted_sum_fusion_3resnet34'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/sample/models'\n",
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t/'\n",
    "PATH_SAMP = '/media/rene/Data/camelyon_out/tiles_224_100t/sample'\n",
    "num_workers = 4\n",
    "batch_size=32\n",
    "sz=224\n",
    "\n",
    "model_list = [resnet34, resnet34, resnet34]\n",
    "model_name = ['resnet34_scratch_0', 'resnet34_scratch_1', 'resnet34_scratch_2'] \n",
    "\n",
    "dataloaders_valid, dataset_sizes_valid = make_batch_gen(PATH_SAMP, batch_size, num_workers, valid_name='valid')\n",
    "dataloaders_test, dataset_sizes_test = make_batch_gen(PATH, batch_size, num_workers, valid_name='test')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_list_ft = []    \n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    # get the proper model architecture\n",
    "    model_ft = model_arch(pretrained=True)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "    # load the saved weights\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name[idx])))\n",
    "    model_list_ft.append(model_ft)\n",
    "\n",
    "batch_size = 8\n",
    "num_workers = 4\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers, valid_name='valid')\n",
    "\n",
    "fusion_model = WeightedSum(num_input=6)\n",
    "fusion_model.load_state_dict(torch.load(os.path.join(save_path, 'weighted_sum_fusion_3resnet34')))\n",
    "fusion_model = fusion_model.cuda() \n",
    "\n",
    "print('Validation weighted_sum_fusion_3resnet34: ')\n",
    "eval_fusion_model(fusion_model, model_list_ft, dataloaders_valid['valid'], dataset_sizes_valid['valid'], criterion)\n",
    "\n",
    "print('Test weighted_sum_fusion_3resnet34: ')\n",
    "eval_fusion_model(fusion_model, model_list_ft, dataloaders_test['test'], dataset_sizes_test['test'], criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove redundant outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fusion_model2(model, model_list, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "        \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                inputs = Variable(inputs.cuda())\n",
    "                labels = Variable(labels.cuda())\n",
    "                    \n",
    "                ######### Get model outputs\n",
    "                features = []\n",
    "                for model_tmp in model_list:\n",
    "                    output = model_tmp(inputs)\n",
    "                    output = output[:,0].unsqueeze(1)\n",
    "                    features.append(output)\n",
    "                cat_features = torch.cat(features, 1)\n",
    "                    \n",
    "                ###########\n",
    "                    \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(cat_features)\n",
    "\n",
    "                # for nets that have multiple outputs such as inception\n",
    "                if isinstance(outputs, tuple):\n",
    "                    loss = sum((criterion(o,labels) for o in outputs))\n",
    "                else:\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    _, preds = torch.max(outputs.data, 1)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                else:\n",
    "                    _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0] * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                print('saving model with acc ', epoch_acc)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best valid Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 224\n",
    "\n",
    "model_list = [resnet34, resnet34, resnet34]\n",
    "model_name = ['resnet34', 'resnet34', 'resnet34'] \n",
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/sample/models'\n",
    "\n",
    "batch_size = 8\n",
    "num_workers = 4\n",
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t/sample'\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers)\n",
    "\n",
    "\n",
    "model_list_ft = []    \n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    # get the proper model architecture\n",
    "    model_ft = model_arch(pretrained=False)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    \n",
    "    # load the saved weights\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name[idx]+'_scratch_'+str(idx))))\n",
    "    model_list_ft.append(model_ft)\n",
    "    \n",
    "fusion_model = WeightedSum(num_input=3)\n",
    "fusion_model = fusion_model.cuda() \n",
    "\n",
    "num_epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(fusion_model.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "\n",
    "\n",
    "model = train_fusion_model2(fusion_model, model_list_ft, \n",
    "                    criterion, optimizer_ft, exp_lr_scheduler, num_epochs=num_epochs)\n",
    "torch.save(model.state_dict(), os.path.join(save_path, 'weighted_sum_fusion_3resnet34'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample-3 resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t/sample'\n",
    "num_workers = 4\n",
    "batch_size=64\n",
    "sz=224\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers, valid_name='valid')\n",
    "\n",
    "model_list = [resnet34, resnet34, resnet34]\n",
    "model_name = ['resnet34', 'resnet34', 'resnet34']\n",
    "\n",
    "epochs = 12\n",
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/sample/models'\n",
    "results = []\n",
    "\n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    model_ft = model_arch(pretrained=False)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "\n",
    "    best_acc, model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=epochs)\n",
    "    results.append((model_name[idx], best_acc))\n",
    "    torch.save(model_ft.state_dict(), os.path.join(save_path, model_name[idx]+'_scratch_samp_'+str(idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:  resnet34_scratch_samp_0\n",
      "Loss: 0.2157 Acc: 0.9135\n",
      "Test:  resnet34_scratch_samp_0\n",
      "Loss: 0.3269 Acc: 0.8621\n",
      "Validation:  resnet34_scratch_samp_1\n",
      "Loss: 0.2154 Acc: 0.9143\n",
      "Test:  resnet34_scratch_samp_1\n",
      "Loss: 0.3358 Acc: 0.8537\n",
      "Validation:  resnet34_scratch_samp_2\n",
      "Loss: 0.2089 Acc: 0.9156\n",
      "Test:  resnet34_scratch_samp_2\n",
      "Loss: 0.3168 Acc: 0.8646\n"
     ]
    }
   ],
   "source": [
    "model_list = [resnet34, resnet34, resnet34]\n",
    "model_name = ['resnet34_scratch_samp_0', 'resnet34_scratch_samp_1', 'resnet34_scratch_samp_2']    \n",
    "\n",
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/sample/models'\n",
    "\n",
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t/'\n",
    "num_workers = 4\n",
    "batch_size=64\n",
    "sz=224\n",
    "dataloaders_valid, dataset_sizes_valid = make_batch_gen(PATH, batch_size, num_workers, valid_name='valid')\n",
    "dataloaders_test, dataset_sizes_test = make_batch_gen(PATH, batch_size, num_workers, valid_name='test')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    # get the proper model architecture\n",
    "    model_ft = model_arch(pretrained=False)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    \n",
    "    # load the saved weights\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name[idx])))\n",
    "    print('Validation: ', model_name[idx])\n",
    "    eval_model(model_ft, dataloaders_valid['valid'], dataset_sizes_valid['valid'], criterion)\n",
    "    \n",
    "    print('Test: ', model_name[idx])\n",
    "    eval_model(model_ft, dataloaders_test['test'], dataset_sizes_test['test'], criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3263 Acc: 0.8660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|         | 1/10 [03:28<31:16, 208.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.3013 Acc: 0.8763\n",
      "saving model with acc  0.8763473053892216\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.3008 Acc: 0.8786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|        | 2/10 [06:57<27:49, 208.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.2952 Acc: 0.8787\n",
      "saving model with acc  0.8787425149700598\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.2987 Acc: 0.8783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|       | 3/10 [10:25<24:19, 208.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.3013 Acc: 0.8737\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.2988 Acc: 0.8762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|      | 4/10 [13:54<20:51, 208.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.3040 Acc: 0.8725\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.3053 Acc: 0.8736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|     | 5/10 [17:22<17:22, 208.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.3123 Acc: 0.8716\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.2956 Acc: 0.8779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|    | 6/10 [20:51<13:54, 208.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.2877 Acc: 0.8760\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.3065 Acc: 0.8760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|   | 7/10 [24:19<10:25, 208.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.3118 Acc: 0.8665\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.3031 Acc: 0.8778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|  | 8/10 [27:48<06:57, 208.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.3181 Acc: 0.8671\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.3005 Acc: 0.8759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%| | 9/10 [31:17<03:28, 208.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.2986 Acc: 0.8814\n",
      "saving model with acc  0.881437125748503\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.2995 Acc: 0.8791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|| 10/10 [34:45<00:00, 208.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.2940 Acc: 0.8769\n",
      "Training complete in 34m 46s\n",
      "Best valid Acc: 0.881437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sz = 224\n",
    "\n",
    "model_list = [resnet34, resnet34, resnet34]\n",
    "model_name = ['resnet34_scratch_samp_0', 'resnet34_scratch_samp_1', 'resnet34_scratch_samp_2']    \n",
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/sample/models'\n",
    "\n",
    "batch_size = 8\n",
    "num_workers = 4\n",
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t/sample'\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers)\n",
    "\n",
    "\n",
    "model_list_ft = []    \n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    # get the proper model architecture\n",
    "    model_ft = model_arch(pretrained=False)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    \n",
    "    # load the saved weights\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name[idx])))\n",
    "    model_list_ft.append(model_ft)\n",
    "    \n",
    "fusion_model = WeightedSum(num_input=6)\n",
    "fusion_model = fusion_model.cuda() \n",
    "\n",
    "num_epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(fusion_model.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "\n",
    "\n",
    "model = train_fusion_model(fusion_model, model_list_ft, \n",
    "                    criterion, optimizer_ft, exp_lr_scheduler, num_epochs=num_epochs)\n",
    "torch.save(model.state_dict(), os.path.join(save_path, 'weighted_sum_fusion_3resnet34_samp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation weighted_sum_fusion_3resnet34_scratch_samp: \n",
      "Loss: 0.2321 Acc: 0.9045\n",
      "Test weighted_sum_fusion_3resnet34_scratch_samp: \n",
      "Loss: 0.3163 Acc: 0.8656\n"
     ]
    }
   ],
   "source": [
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/sample/models'\n",
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t/'\n",
    "PATH_SAMP = '/media/rene/Data/camelyon_out/tiles_224_100t/sample'\n",
    "num_workers = 4\n",
    "batch_size=32\n",
    "sz=224\n",
    "\n",
    "model_list = [resnet34, resnet34, resnet34]\n",
    "model_name = ['resnet34_scratch_samp_0', 'resnet34_scratch_samp_1', 'resnet34_scratch_samp_2']    \n",
    "\n",
    "dataloaders_valid, dataset_sizes_valid = make_batch_gen(PATH_SAMP, batch_size, num_workers, valid_name='valid')\n",
    "dataloaders_test, dataset_sizes_test = make_batch_gen(PATH, batch_size, num_workers, valid_name='test')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_list_ft = []    \n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    # get the proper model architecture\n",
    "    model_ft = model_arch(pretrained=True)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "    # load the saved weights\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name[idx])))\n",
    "    model_list_ft.append(model_ft)\n",
    "\n",
    "batch_size = 8\n",
    "num_workers = 4\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers, valid_name='valid')\n",
    "\n",
    "fusion_model = WeightedSum(num_input=6)\n",
    "fusion_model.load_state_dict(torch.load(os.path.join(save_path, 'weighted_sum_fusion_3resnet34_samp')))\n",
    "fusion_model = fusion_model.cuda() \n",
    "\n",
    "print('Validation weighted_sum_fusion_3resnet34_scratch_samp: ')\n",
    "eval_fusion_model(fusion_model, model_list_ft, dataloaders_valid['valid'], dataset_sizes_valid['valid'], criterion)\n",
    "\n",
    "print('Test weighted_sum_fusion_3resnet34_scratch_samp: ')\n",
    "eval_fusion_model(fusion_model, model_list_ft, dataloaders_test['test'], dataset_sizes_test['test'], criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not Sample-3 resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_batch_gen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-98bce8067df7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_batch_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresnet34\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet34\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet34\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet34\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet34\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet34\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_batch_gen' is not defined"
     ]
    }
   ],
   "source": [
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t/'\n",
    "num_workers = 4\n",
    "batch_size=64\n",
    "sz=224\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers, valid_name='valid')\n",
    "\n",
    "model_list = [resnet34, resnet34, resnet34, resnet34, resnet34, resnet34]\n",
    "model_name = ['resnet34', 'resnet34', 'resnet34', 'resnet34', 'resnet34', 'resnet34']\n",
    "\n",
    "epochs = 12\n",
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/models'\n",
    "results = []\n",
    "\n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    model_ft = model_arch(pretrained=False)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "\n",
    "    best_acc, model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=epochs)\n",
    "    results.append((model_name[idx], best_acc))\n",
    "    torch.save(model_ft.state_dict(), os.path.join(save_path, model_name[idx]+'_scratch_no_samp_'+str(idx+6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:  resnet34_scratch_no_samp_0\n",
      "Loss: 0.1684 Acc: 0.9304\n",
      "Test:  resnet34_scratch_no_samp_0\n",
      "Loss: 0.3462 Acc: 0.8566\n",
      "Validation:  resnet34_scratch_no_samp_1\n",
      "Loss: 0.1701 Acc: 0.9317\n",
      "Test:  resnet34_scratch_no_samp_1\n",
      "Loss: 0.3325 Acc: 0.8584\n",
      "Validation:  resnet34_scratch_no_samp_2\n",
      "Loss: 0.1720 Acc: 0.9278\n",
      "Test:  resnet34_scratch_no_samp_2\n",
      "Loss: 0.3804 Acc: 0.8389\n",
      "Validation:  resnet34_scratch_no_samp_3\n",
      "Loss: 0.1605 Acc: 0.9338\n",
      "Test:  resnet34_scratch_no_samp_3\n",
      "Loss: 0.3317 Acc: 0.8577\n",
      "Validation:  resnet34_scratch_no_samp_4\n",
      "Loss: 0.1672 Acc: 0.9302\n",
      "Test:  resnet34_scratch_no_samp_4\n",
      "Loss: 0.3455 Acc: 0.8520\n",
      "Validation:  resnet34_scratch_no_samp_5\n",
      "Loss: 0.1762 Acc: 0.9278\n",
      "Test:  resnet34_scratch_no_samp_5\n",
      "Loss: 0.3603 Acc: 0.8350\n",
      "Validation:  resnet34_scratch_no_samp_6\n",
      "Loss: 0.1673 Acc: 0.9311\n",
      "Test:  resnet34_scratch_no_samp_6\n",
      "Loss: 0.3444 Acc: 0.8511\n",
      "Validation:  resnet34_scratch_no_samp_7\n",
      "Loss: 0.1607 Acc: 0.9332\n",
      "Test:  resnet34_scratch_no_samp_7\n",
      "Loss: 0.3426 Acc: 0.8571\n",
      "Validation:  resnet34_scratch_no_samp_8\n",
      "Loss: 0.1642 Acc: 0.9305\n",
      "Test:  resnet34_scratch_no_samp_8\n",
      "Loss: 0.3365 Acc: 0.8495\n",
      "Validation:  resnet34_scratch_no_samp_9\n",
      "Loss: 0.1720 Acc: 0.9286\n",
      "Test:  resnet34_scratch_no_samp_9\n",
      "Loss: 0.3215 Acc: 0.8641\n",
      "Validation:  resnet34_scratch_no_samp_10\n",
      "Loss: 0.1651 Acc: 0.9297\n",
      "Test:  resnet34_scratch_no_samp_10\n",
      "Loss: 0.3489 Acc: 0.8496\n",
      "Validation:  resnet34_scratch_no_samp_11\n",
      "Loss: 0.1659 Acc: 0.9314\n",
      "Test:  resnet34_scratch_no_samp_11\n",
      "Loss: 0.3366 Acc: 0.8537\n"
     ]
    }
   ],
   "source": [
    "model_list = [resnet34, resnet34, resnet34, resnet34, resnet34, resnet34, resnet34, resnet34, resnet34,resnet34, resnet34, resnet34]\n",
    "model_name = ['resnet34_scratch_no_samp_0', 'resnet34_scratch_no_samp_1', 'resnet34_scratch_no_samp_2',\n",
    "    'resnet34_scratch_no_samp_3', 'resnet34_scratch_no_samp_4', 'resnet34_scratch_no_samp_5',\n",
    "    'resnet34_scratch_no_samp_6', 'resnet34_scratch_no_samp_7', 'resnet34_scratch_no_samp_8',\n",
    "    'resnet34_scratch_no_samp_9', 'resnet34_scratch_no_samp_10', 'resnet34_scratch_no_samp_11']  \n",
    "\n",
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/models'\n",
    "\n",
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t/'\n",
    "num_workers = 4\n",
    "batch_size=64\n",
    "sz=224\n",
    "dataloaders_valid, dataset_sizes_valid = make_batch_gen(PATH, batch_size, num_workers, valid_name='valid')\n",
    "dataloaders_test, dataset_sizes_test = make_batch_gen(PATH, batch_size, num_workers, valid_name='test')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "results = {}\n",
    "\n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    # get the proper model architecture\n",
    "    model_ft = model_arch(pretrained=False)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    \n",
    "    # load the saved weights\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name[idx])))\n",
    "    print('Validation: ', model_name[idx])\n",
    "    valid_loss, valid_acc = eval_model(model_ft, dataloaders_valid['valid'], dataset_sizes_valid['valid'], criterion)\n",
    "    \n",
    "    print('Test: ', model_name[idx])\n",
    "    test_loss, test_acc = eval_model(model_ft, dataloaders_test['test'], dataset_sizes_test['test'], criterion)\n",
    "    \n",
    "    results[model_name[idx]] = [valid_acc, test_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2511 Acc: 0.9001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|         | 1/10 [19:00<2:51:05, 1140.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.2333 Acc: 0.9051\n",
      "saving model with acc  0.9050898203592814\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "sz = 224\n",
    "\n",
    "model_list = [resnet34, resnet34, resnet34]\n",
    "model_name = ['resnet34_scratch_no_samp_0', 'resnet34_scratch_no_samp_1', 'resnet34_scratch_no_samp_2']    \n",
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/models'\n",
    "\n",
    "batch_size = 8\n",
    "num_workers = 4\n",
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t'\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers)\n",
    "\n",
    "\n",
    "model_list_ft = []    \n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    # get the proper model architecture\n",
    "    model_ft = model_arch(pretrained=False)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    \n",
    "    # load the saved weights\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name[idx])))\n",
    "    model_list_ft.append(model_ft)\n",
    "    \n",
    "fusion_model = WeightedSum(num_input=6)\n",
    "fusion_model = fusion_model.cuda() \n",
    "\n",
    "num_epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(fusion_model.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "\n",
    "\n",
    "model = train_fusion_model(fusion_model, model_list_ft, \n",
    "                    criterion, optimizer_ft, exp_lr_scheduler, num_epochs=num_epochs)\n",
    "torch.save(model.state_dict(), os.path.join(save_path, 'weighted_sum_fusion_3resnet34_nosamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation weighted_sum_fusion_3resnet34_scratch_nosamp: \n",
      "Loss: 0.1819 Acc: 0.9237\n",
      "Test weighted_sum_fusion_3resnet34_scratch_nosamp: \n",
      "Loss: 0.2747 Acc: 0.8803\n"
     ]
    }
   ],
   "source": [
    "save_path = '/media/rene/Data/camelyon_out/tiles_224_100t/models'\n",
    "PATH = '/media/rene/Data/camelyon_out/tiles_224_100t/'\n",
    "num_workers = 4\n",
    "batch_size=32\n",
    "sz=224\n",
    "\n",
    "model_list = [resnet34, resnet34, resnet34]\n",
    "model_name = ['resnet34_scratch_no_samp_0', 'resnet34_scratch_no_samp_1', 'resnet34_scratch_no_samp_2']    \n",
    "\n",
    "dataloaders_valid, dataset_sizes_valid = make_batch_gen(PATH, batch_size, num_workers, valid_name='valid')\n",
    "dataloaders_test, dataset_sizes_test = make_batch_gen(PATH, batch_size, num_workers, valid_name='test')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_list_ft = []    \n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    # get the proper model architecture\n",
    "    model_ft = model_arch(pretrained=True)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "    # load the saved weights\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name[idx])))\n",
    "    model_list_ft.append(model_ft)\n",
    "\n",
    "batch_size = 8\n",
    "num_workers = 4\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers, valid_name='valid')\n",
    "\n",
    "fusion_model = WeightedSum(num_input=6)\n",
    "fusion_model.load_state_dict(torch.load(os.path.join(save_path, 'weighted_sum_fusion_3resnet34_nosamp')))\n",
    "fusion_model = fusion_model.cuda() \n",
    "\n",
    "print('Validation weighted_sum_fusion_3resnet34_scratch_nosamp: ')\n",
    "eval_fusion_model(fusion_model, model_list_ft, dataloaders_valid['valid'], dataset_sizes_valid['valid'], criterion)\n",
    "\n",
    "print('Test weighted_sum_fusion_3resnet34_scratch_nosamp: ')\n",
    "eval_fusion_model(fusion_model, model_list_ft, dataloaders_test['test'], dataset_sizes_test['test'], criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion mmodel using only the best 3 resnet34s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
